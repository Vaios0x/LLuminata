# ğŸ˜ MigraciÃ³n a PostgreSQL - InclusiveAI Coach

## ğŸ“‹ Resumen

Este documento describe la migraciÃ³n completa del sistema de base de datos de SQLite a PostgreSQL para el proyecto InclusiveAI Coach, incluyendo configuraciÃ³n de pool de conexiones, backup automÃ¡tico y migraciones de producciÃ³n.

## ğŸ¯ Objetivos de la MigraciÃ³n

### âœ… Beneficios de PostgreSQL

1. **Escalabilidad**: Soporte para mÃºltiples conexiones concurrentes
2. **Rendimiento**: Optimizaciones avanzadas y Ã­ndices mejorados
3. **Confiabilidad**: ACID compliance y transacciones robustas
4. **Funcionalidades Avanzadas**: JSON, bÃºsqueda full-text, particionamiento
5. **Monitoreo**: Herramientas integradas de monitoreo y auditorÃ­a
6. **Backup**: Estrategias de backup mÃ¡s robustas

### ğŸ”§ Mejoras Implementadas

- **Pool de Conexiones**: ConfiguraciÃ³n optimizada para alta concurrencia
- **Backup AutomÃ¡tico**: Sistema de backup con compresiÃ³n y rotaciÃ³n
- **Migraciones de ProducciÃ³n**: Scripts seguros con rollback automÃ¡tico
- **Monitoreo**: IntegraciÃ³n con Prometheus y Grafana
- **AuditorÃ­a**: Sistema de logs para cambios en la base de datos

## ğŸ—ï¸ Arquitectura de la MigraciÃ³n

### Componentes Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application   â”‚    â”‚   PostgreSQL    â”‚    â”‚   Monitoring    â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   Database      â”‚â—„â”€â”€â–ºâ”‚   (Prometheus)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Connection    â”‚    â”‚   Backup        â”‚    â”‚   Grafana       â”‚
â”‚   Pool          â”‚    â”‚   System        â”‚    â”‚   Dashboard     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

1. **AplicaciÃ³n** â†’ **Pool de Conexiones** â†’ **PostgreSQL**
2. **PostgreSQL** â†’ **Backup AutomÃ¡tico** â†’ **Almacenamiento**
3. **PostgreSQL** â†’ **Monitoreo** â†’ **Grafana Dashboard**

## ğŸš€ Proceso de MigraciÃ³n

### 1. PreparaciÃ³n

```bash
# Clonar el repositorio
git clone <repository-url>
cd inclusive-ai-coach

# Instalar dependencias
npm install

# Configurar variables de entorno
cp env.example .env
```

### 2. ConfiguraciÃ³n de Variables de Entorno

```bash
# PostgreSQL Configuration
DATABASE_URL="postgresql://inclusive:inclusive123@localhost:5432/inclusive_ai"
DIRECT_URL="postgresql://inclusive:inclusive123@localhost:5432/inclusive_ai"

# Pool Configuration
DATABASE_POOL_MIN=2
DATABASE_POOL_MAX=10
DATABASE_POOL_TIMEOUT=30000

# Backup Configuration
BACKUP_ENABLED=true
BACKUP_RETENTION_DAYS=7
BACKUP_COMPRESS=true
```

### 3. Iniciar Servicios con Docker

```bash
# Desarrollo
docker-compose up -d

# ProducciÃ³n
docker-compose -f docker-compose.prod.yml up -d
```

### 4. Ejecutar MigraciÃ³n

```bash
# MigraciÃ³n inicial
npm run db:migrate-to-postgresql

# Verificar migraciÃ³n
npm run db:health-check

# Generar cliente Prisma
npm run db:generate
```

### 5. Configurar Backup AutomÃ¡tico

```bash
# Configurar cron jobs
chmod +x ./scripts/setup-cron.sh
./scripts/setup-cron.sh

# Verificar configuraciÃ³n
./scripts/setup-cron.sh --list
```

## ğŸ“Š ConfiguraciÃ³n de Pool de Conexiones

### ConfiguraciÃ³n en `lib/database.ts`

```typescript
export const prisma = new PrismaClient({
  log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
  datasources: {
    db: {
      url: process.env.DATABASE_URL,
    },
  },
  // ConfiguraciÃ³n de pool de conexiones
  __internal: {
    engine: {
      connectionLimit: 20,
      pool: {
        min: 2,
        max: 10,
        acquireTimeoutMillis: 30000,
        createTimeoutMillis: 30000,
        destroyTimeoutMillis: 5000,
        idleTimeoutMillis: 30000,
        reapIntervalMillis: 1000,
        createRetryIntervalMillis: 200,
      },
    },
  },
})
```

### ParÃ¡metros de Pool

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `min` | 2 | Conexiones mÃ­nimas en el pool |
| `max` | 10 | Conexiones mÃ¡ximas en el pool |
| `acquireTimeoutMillis` | 30000 | Tiempo mÃ¡ximo para obtener conexiÃ³n |
| `idleTimeoutMillis` | 30000 | Tiempo mÃ¡ximo de inactividad |
| `createRetryIntervalMillis` | 200 | Intervalo entre reintentos |

## ğŸ”„ Sistema de Backup

### Script de Backup AutomÃ¡tico

**Archivo**: `scripts/backup-postgresql.sh`

**CaracterÃ­sticas**:
- âœ… Backup comprimido con gzip
- âœ… RotaciÃ³n automÃ¡tica de backups
- âœ… VerificaciÃ³n de integridad
- âœ… Upload opcional a S3
- âœ… Logging detallado
- âœ… Reportes de backup

### Uso del Script

```bash
# Backup bÃ¡sico
./scripts/backup-postgresql.sh

# Backup con compresiÃ³n
./scripts/backup-postgresql.sh --compress

# Backup con upload a S3
./scripts/backup-postgresql.sh --compress --upload-s3

# Configurar retenciÃ³n personalizada
./scripts/backup-postgresql.sh --retention 14
```

### Cron Jobs Configurados

```bash
# Backup diario a las 2:00 AM
0 2 * * * /path/to/backup-postgresql.sh --compress

# Backup semanal con S3 los domingos a las 3:00 AM
0 3 * * 0 /path/to/backup-postgresql.sh --compress --upload-s3

# Limpieza de logs los domingos a las 4:00 AM
0 4 * * 0 find /path/to/logs -name '*.log' -mtime +30 -delete

# VerificaciÃ³n de salud cada 30 minutos
*/30 * * * * cd /path/to/app && npm run db:health-check
```

## ğŸ­ Migraciones de ProducciÃ³n

### Script de MigraciÃ³n de ProducciÃ³n

**Archivo**: `scripts/production-migration.ts`

**CaracterÃ­sticas**:
- âœ… Backup automÃ¡tico antes de migraciÃ³n
- âœ… ValidaciÃ³n de salud de la base de datos
- âœ… Reintentos automÃ¡ticos en caso de fallo
- âœ… Rollback automÃ¡tico en caso de error
- âœ… Reportes detallados de migraciÃ³n
- âœ… VerificaciÃ³n post-migraciÃ³n

### Proceso de MigraciÃ³n de ProducciÃ³n

```bash
# 1. Verificar salud inicial
npm run db:health-check

# 2. Crear backup de producciÃ³n
npm run db:backup

# 3. Ejecutar migraciÃ³n de producciÃ³n
npm run db:production-migration

# 4. Verificar migraciÃ³n
npm run db:health-check
```

### Validaciones Implementadas

1. **Salud de Base de Datos**
   - VerificaciÃ³n de conexiÃ³n
   - Conteo de registros en tablas crÃ­ticas
   - VerificaciÃ³n de conexiones activas

2. **Integridad de Datos**
   - VerificaciÃ³n de todas las tablas
   - ValidaciÃ³n de Ã­ndices crÃ­ticos
   - ComprobaciÃ³n de relaciones

3. **Rendimiento**
   - AnÃ¡lisis de consultas lentas
   - EstadÃ­sticas de rendimiento
   - Monitoreo de uso de recursos

## ğŸ“ˆ Monitoreo y MÃ©tricas

### ConfiguraciÃ³n de Prometheus

**Archivo**: `monitoring/prometheus.yml`

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres:5432']
    metrics_path: '/metrics'
    scrape_interval: 30s
```

### MÃ©tricas Monitoreadas

1. **Conexiones**
   - Conexiones activas
   - Conexiones inactivas
   - Conexiones totales

2. **Rendimiento**
   - Tiempo de respuesta de consultas
   - Consultas lentas
   - Uso de cache

3. **Recursos**
   - Uso de memoria
   - Uso de CPU
   - Espacio en disco

4. **Backup**
   - Estado de backups
   - TamaÃ±o de backups
   - Tiempo de backup

### Dashboard de Grafana

**URL**: `http://localhost:3001`

**Paneles Incluidos**:
- Estado general de la base de datos
- MÃ©tricas de rendimiento
- EstadÃ­sticas de conexiones
- Estado de backups
- Alertas y notificaciones

## ğŸ”§ Optimizaciones de PostgreSQL

### ConfiguraciÃ³n de Rendimiento

```sql
-- ConfiguraciÃ³n de memoria
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET work_mem = '4MB';

-- ConfiguraciÃ³n de WAL
ALTER SYSTEM SET wal_level = replica;
ALTER SYSTEM SET max_wal_senders = 3;
ALTER SYSTEM SET wal_keep_segments = 32;

-- ConfiguraciÃ³n de autovacuum
ALTER SYSTEM SET autovacuum = on;
ALTER SYSTEM SET autovacuum_max_workers = 3;
ALTER SYSTEM SET autovacuum_vacuum_threshold = 50;
```

### Ãndices de Rendimiento

```sql
-- Ãndices para consultas frecuentes
CREATE INDEX IF NOT EXISTS idx_student_location ON "Student"("location");
CREATE INDEX IF NOT EXISTS idx_student_language ON "Student"("language");
CREATE INDEX IF NOT EXISTS idx_completed_lesson_student ON "CompletedLesson"("studentId");
CREATE INDEX IF NOT EXISTS idx_assessment_student ON "Assessment"("studentId");
CREATE INDEX IF NOT EXISTS idx_user_email ON "User"("email");
```

### Extensiones Ãštiles

```sql
-- Extensiones para funcionalidades avanzadas
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
CREATE EXTENSION IF NOT EXISTS "btree_gin";
```

## ğŸ›¡ï¸ Seguridad y AuditorÃ­a

### Sistema de AuditorÃ­a

**Tabla**: `audit_log`

```sql
CREATE TABLE audit_log (
    id uuid DEFAULT uuid_generate_v4() PRIMARY KEY,
    table_name text NOT NULL,
    operation text NOT NULL,
    old_data jsonb,
    new_data jsonb,
    user_id text,
    timestamp timestamptz DEFAULT NOW()
);
```

### Triggers de AuditorÃ­a

```sql
-- Trigger para registrar cambios
CREATE OR REPLACE FUNCTION audit_trigger()
RETURNS trigger AS $$
BEGIN
    IF TG_OP = 'INSERT' THEN
        INSERT INTO audit_log (table_name, operation, new_data, user_id)
        VALUES (TG_TABLE_NAME, 'INSERT', to_jsonb(NEW), current_setting('app.current_user_id', true));
        RETURN NEW;
    ELSIF TG_OP = 'UPDATE' THEN
        INSERT INTO audit_log (table_name, operation, old_data, new_data, user_id)
        VALUES (TG_TABLE_NAME, 'UPDATE', to_jsonb(OLD), to_jsonb(NEW), current_setting('app.current_user_id', true));
        RETURN NEW;
    ELSIF TG_OP = 'DELETE' THEN
        INSERT INTO audit_log (table_name, operation, old_data, user_id)
        VALUES (TG_TABLE_NAME, 'DELETE', to_jsonb(OLD), current_setting('app.current_user_id', true));
        RETURN OLD;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
```

## ğŸ“‹ Scripts Disponibles

### Comandos NPM

```bash
# MigraciÃ³n y gestiÃ³n de base de datos
npm run db:migrate-to-postgresql    # MigraciÃ³n inicial
npm run db:production-migration     # MigraciÃ³n de producciÃ³n
npm run db:deploy                   # Aplicar migraciones
npm run db:generate                 # Generar cliente Prisma
npm run db:health-check             # Verificar salud
npm run db:backup                   # Backup manual
npm run db:backup-s3                # Backup con S3

# Desarrollo
npm run dev                         # Servidor de desarrollo
npm run build                       # Build de producciÃ³n
npm run start                       # Servidor de producciÃ³n
```

### Scripts de Sistema

```bash
# Backup
./scripts/backup-postgresql.sh --compress

# ConfiguraciÃ³n de cron
./scripts/setup-cron.sh
./scripts/setup-cron.sh --list
./scripts/setup-cron.sh --remove

# MigraciÃ³n
tsx scripts/migrate-to-postgresql.ts
tsx scripts/production-migration.ts
```

## ğŸ” Troubleshooting

### Problemas Comunes

1. **Error de ConexiÃ³n**
   ```bash
   # Verificar que PostgreSQL estÃ¡ ejecutÃ¡ndose
   docker-compose ps
   
   # Verificar variables de entorno
   echo $DATABASE_URL
   
   # Probar conexiÃ³n
   npm run db:health-check
   ```

2. **Error de MigraciÃ³n**
   ```bash
   # Verificar estado de migraciones
   npx prisma migrate status
   
   # Resetear migraciones (solo desarrollo)
   npx prisma migrate reset
   
   # Verificar logs
   tail -f ./backups/cron.log
   ```

3. **Error de Backup**
   ```bash
   # Verificar permisos
   ls -la ./scripts/backup-postgresql.sh
   
   # Ejecutar backup manual
   ./scripts/backup-postgresql.sh --compress
   
   # Verificar espacio en disco
   df -h
   ```

### Logs y Monitoreo

```bash
# Logs de aplicaciÃ³n
docker-compose logs app

# Logs de PostgreSQL
docker-compose logs postgres

# Logs de backup
tail -f ./backups/cron.log

# MÃ©tricas de Prometheus
curl http://localhost:9090/metrics
```

## ğŸ“š Referencias

### DocumentaciÃ³n Oficial

- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Prisma Documentation](https://www.prisma.io/docs/)
- [Docker Compose Documentation](https://docs.docker.com/compose/)

### Herramientas Relacionadas

- [pgAdmin](https://www.pgadmin.org/) - Interfaz grÃ¡fica para PostgreSQL
- [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html) - EstadÃ­sticas de consultas
- [Prometheus](https://prometheus.io/) - Monitoreo y alertas
- [Grafana](https://grafana.com/) - Dashboards y visualizaciÃ³n

## ğŸ‰ ConclusiÃ³n

La migraciÃ³n a PostgreSQL proporciona una base sÃ³lida para el crecimiento y escalabilidad del proyecto InclusiveAI Coach. Con las optimizaciones implementadas, el sistema ahora cuenta con:

- âœ… **Alta disponibilidad** con pool de conexiones optimizado
- âœ… **Backup automÃ¡tico** con rotaciÃ³n y compresiÃ³n
- âœ… **Monitoreo completo** con mÃ©tricas en tiempo real
- âœ… **AuditorÃ­a detallada** de todos los cambios
- âœ… **Migraciones seguras** con rollback automÃ¡tico
- âœ… **DocumentaciÃ³n completa** para mantenimiento

El sistema estÃ¡ listo para manejar cargas de producciÃ³n y proporcionar una experiencia confiable para los usuarios de InclusiveAI Coach.

---

**Nota**: Esta migraciÃ³n mantiene la compatibilidad con todas las funcionalidades existentes mientras proporciona una base mÃ¡s robusta para el futuro crecimiento del proyecto.
